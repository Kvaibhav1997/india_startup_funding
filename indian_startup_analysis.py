# -*- coding: utf-8 -*-
"""Indian_Startup_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T08Su3Ad2musYcjkpzEYRimFCMlc8a_u
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
# %matplotlib inline

"""Importing dataset present in dataset folder"""

from google.colab import drive
drive.mount('/content/drive')

data=pd.read_csv('/content/drive/MyDrive/My Colab Dataset/startup_funding.csv')

"""High level overview of the data we are dealing with"""

data.head()

data.tail()

print('data contains',data.shape[0],'rows and',data.shape[1],'columns',sep=' ')

"""**Lets see the columns (features) we have available.**"""

print(data.info())

null_values=pd.isnull(data).sum()
columns=null_values.index
frequency=null_values.values
percentage=(frequency/data.shape[0])*100
missing_values=pd.DataFrame({'Columns':columns,'Missing Data':frequency,'Percentage':percentage}).sort_values('Percentage',ascending=False).set_index('Columns')
missing_values

data.drop(columns=['Remarks'],inplace=True)
data.drop(columns=['SNo'],inplace=True)

null_values=pd.isnull(data).sum()
columns=null_values.index
frequency=null_values.values
percentage=(frequency/data.shape[0])*100
missing_values=pd.DataFrame({'Columns':columns,'Missing Data':frequency,'Percentage':percentage}).sort_values('Percentage',ascending=False).set_index('Columns')
missing_values

"""Now, lets go one by one and try to fill out missing values in each column.

# **SubVertical**
"""

data['SubVertical'].describe()

len(data['SubVertical'].unique())

"""There are 1365 unique sub-categories and 936 unknown sub-categories

We have two options from here, that is,
1.   Fill up the missing values as 'Not specified' string
2.   Do not fill up the missing values.

For this analysis, we intend to not fill up the missing values for the SubVertical columns since later on, it might affect our analysis.
"""

data['SubVertical'].fillna(value='Not Specified or Other',inplace=True)

"""# **AmountInUSD**"""

data['AmountInUSD'].head()

"""We see that the column is not in numeric format, so lets correct the format and then try to fill up the missing values"""

data['AmountInUSD']=data['AmountInUSD'].apply(lambda x: float(str(x).replace(',','')))

import math
data['AmountInUSD'].describe().apply(lambda x: math.ceil(x))
# applied math.ceil() to express the numbers in normal format instead of exponential

data[data['AmountInUSD'].isnull()].shape

"""# **CityLocation**

The missing value for cities can be filled by 'Not Specified"
"""

data['CityLocation'].head(10)

data['CityLocation'].describe()

data[data['CityLocation'].isnull()].shape

"""There are 179 null values in CityLocation. that is 7% of the entire data set. Let's fill up the null values with "Not Specific".
Also, if we see closely, some rows have multiple cities, So lets clean them up and just use one city name.
"""

data['CityLocation'].fillna(value='Not Specified',inplace=True)

"""Making a function to check if multiple cities are mentioned separated by '/', if yes, then replace it with the first name."""

def city_cleaner(x):
    return x.split('/')[0].strip()

data['CityLocation']=data['CityLocation'].apply(city_cleaner)

data['CityLocation'].value_counts().head(15)

"""# **IndustryVertical**

IndustryVertical has 171 null values, filling those rows with value 'Other'.
Also, IndustryVertical consists of some duplicate values with different caps. To sort this, lets convert all to lowercase so that all have same caps
"""

data['IndustryVertical'].head(10)

data['IndustryVertical'].fillna('Others',inplace=True)

data['IndustryVertical']=data['IndustryVertical'].apply(lambda x: x.lower())

"""
# **InvestorsName**"""

data['InvestorsName'].value_counts().head()

"""InvestorsName has 8 null values, filling those rows with value 'Undisclosed Investors'.
Also we need to change 'Undisclosed investors' to 'Undisclosed Investors'
"""

data['InvestorsName'].fillna(value='Undisclosed Investors',inplace=True)
data['InvestorsName']=data['InvestorsName'].replace('Undisclosed investors','Undisclosed Investors')

data['InvestorsName'].value_counts().head()

"""
# **InvestmentType**"""

data['InvestmentType'].describe()

"""Let's fill up the 1 missing value in InvestmentType with the most common value, that is, Seed Funding"""

data['InvestmentType'].fillna('Seed Funding',inplace=True)

"""
# **Date**"""

data['Date'].describe()

"""When we initially tried to convert Date column to date time, several errors popped up due to bad format ('.' instead of '/' and so on. So cleaned the strings, then converted to datetime"""

data['Date']=data['Date'].apply(lambda x: str(x).replace('.','/'))
data['Date']=data['Date'].apply(lambda x: str(x).replace('//','/'))

data['Date']=pd.to_datetime(data['Date'])

data.head()

data=data.sort_values('Date',ascending=False).reset_index()

data.head()

"""
# **StartupName**"""

data['StartupName']=data['StartupName'].apply(lambda x: x.lower())

"""While exploring the data, it was found that there have been separate names for same startups due to difference in spellings. So let's remove all ambiguous names."""

data['StartupName']=data['StartupName'].apply(lambda x: str(x).replace('ola cabs','ola'))
data['StartupName']=data['StartupName'].apply(lambda x: str(x).replace('olacabs','ola'))
data['StartupName']=data['StartupName'].apply(lambda x: str(x).replace('flipkart.com','flipkart'))
data['StartupName']=data['StartupName'].apply(lambda x: str(x).replace('paytm marketplace','paytm'))

print('Number of unique startups funded:',data['StartupName'].nunique())

"""# **Exploring the Data**"""

# This method allows us to make the ticks showed in x-axis more readable by inserting newlines, We can pass in
# a series and it returns a formatted index series
def ticks_display_cleaner(series):
    putSpace=True
    index=list(series.index)
    values=list(series.values)
    for i in range(len(index)):
        c=index[i].strip().split(' ')
        if len(c)>2:
            c.insert(2,'\n')
        if len(c)>5:
            c.insert(5,'\n')
        for j in range(len(c)):
            if c[j]!='\n':
                c[j]=c[j]+' '
        index[i]=''.join(c)
    return pd.Series(values,index=index)

"""# **Q1. Top 20 Startups on the basis of funds acquired**"""

top_20_startups=pd.DataFrame(data.groupby('StartupName')['AmountInUSD'].sum().sort_values(ascending=False).reset_index().head(20))
top_20_startups['AmountInUSD']=top_20_startups['AmountInUSD'].apply(lambda x: math.ceil(x))
top_20_startups

plt.figure(figsize=(20,15))
plt.title('TOP 20 STARTUPS',fontsize=25)
plt.xticks(fontsize=19,rotation='vertical')
plt.ylabel('Amount In USD',fontsize=20)
sns.barplot(x='StartupName',y='AmountInUSD',data=top_20_startups)
plt.savefig('top20startups.png',dpi=300)
plt.show()

"""The above Output shows the top 20 startups funded between January 2015 to December 2017.
Paytm and Flipkart are the highest funded startups.

# **Q2. Startup(s) which acquired the minimum amount of funds**
"""

print('Minimum funds acquired by a startup: ',data['AmountInUSD'].describe()['min'])

data[data['AmountInUSD']==16000]

"""**Yo Grad, Hostel Dunia, Plan Your Sport, Enabli**, and **CBS** are the startups who acquired least funding, that is, \$16000

# **Q3. Which Industry has maximum number of startups?**
"""

df=data[data['IndustryVertical']!='others']
top_10_industries=df['IndustryVertical'].value_counts().sort_values(ascending=False).head(10)
print(top_10_industries)
top_10_industries=ticks_display_cleaner(top_10_industries)

plt.figure(figsize=(25,15))
plt.xlabel('Industries',fontsize=16)
plt.ylabel('Count',fontsize=16)
plt.title('Count of Startups in Industries',fontsize=22)
plt.xticks(fontsize=17)
sns.barplot(top_10_industries.index,top_10_industries.values)
plt.savefig('Industries.png',dpi=300)

"""The top 3 industries having max number of startups are:

Consumer Internet
Technology
ECommerce
"""

df=data[data['SubVertical']!='Not Specified or Other']
df['SubVertical'].value_counts(ascending=False).head(10)

"""# **Lets have a look at each industry from a closer point of view**
**1. Consumer Internet**

Checking out top 10 sub-categories of industry having highest number of startups
"""

ci=data[data['IndustryVertical']=='consumer internet']
top_10_ci_sub=ci['SubVertical'].value_counts().sort_values(ascending=False).head(10)
top_10_ci_sub=ticks_display_cleaner(top_10_ci_sub)
plt.figure(figsize=(25,15))
plt.xticks(fontsize=14)
plt.title('Consumer Internet Sub-Category',fontsize=22)
plt.xlabel('Sub-Categories',fontsize=19)
plt.ylabel('Count',fontsize=19)
sns.barplot(top_10_ci_sub.index,top_10_ci_sub.values)
plt.savefig('Consumer-Internet.png',dpi=300)

"""**Food Delivery Platform** has 8 startups, followed by **Online Lending Platform, Online Learning Platform, and Fitness Mobile App** having 5,4, and 3 startups listed respectively

**Top consumer internet startups**
"""

ci.groupby('StartupName')['AmountInUSD'].sum().sort_values(ascending=False).astype(int).head(10).reset_index()

"""**2. Technology**"""

tech=data[data['IndustryVertical']=='technology']

"""**Top Technology based startups on the basis of funds acquired**"""

tech.groupby('StartupName')['AmountInUSD'].sum().sort_values(ascending=False).astype(int).head(10).reset_index()

"""**Delhivery, Fractal Analytics, Rivigo** are top Technology based startups

# **3. ECommerce**
"""

commerce=data[data['IndustryVertical']=='ecommerce']

"""**Top ECommerce based startups on the basis of funds acquired**"""

commerce.groupby('StartupName')['AmountInUSD'].sum().sort_values(ascending=False).astype(int).head(10).reset_index()

"""**Paytm, Flipkart, SnapDeal** are top ECommerce based startups with highest amount funded"""

top_10_comm_sub=commerce['SubVertical'].value_counts().sort_values(ascending=False).head(10)
top_10_comm_sub=ticks_display_cleaner(top_10_comm_sub)
plt.figure(figsize=(30,10))
plt.ylabel('Count',fontsize=19)
plt.xticks(fontsize=14)
plt.title('Top 10 Sub-Categories in ECommerce Industry',fontsize=24)
sns.barplot(top_10_comm_sub.index,top_10_comm_sub.values)
plt.savefig('Ecommerce.png',dpi=300)

"""There are 6 startups based on Online Pharmacy sub-category, followed by 3 startups in **ECommerce Marketplace** Sub-Category.

# **Q4. Which period had the most number of startups funded.**
"""

# Creating new columns, Month, Year, Quarter, QuarterYear
# QuarterYear is the concatenation of year+quarter to show the 4 quarters of each year which will be further used
# below in our analysis.
date_year=data['Date'].dt

data['Month']=date_year.month
data['Year']=date_year.year

data['Quarter']=''
data['Year']=data['Year'].astype('object')

data.loc[(data['Month']>=1) & (data['Month']<=3),'Quarter']=str(1)
data.loc[(data['Month']>=4) & (data['Month']<=6),'Quarter']=str(2)
data.loc[(data['Month']>=7) & (data['Month']<=9),'Quarter']=str(3)
data.loc[(data['Month']>=10) & (data['Month']<=12),'Quarter']=str(4)

data['QuarterYear']=data['Year'].astype(str)+"-Q"+data['Quarter'].astype(str)

data.groupby('QuarterYear')['StartupName'].count().sort_values(ascending=False)

plt.figure(figsize=(15,10))
plt.title('Quarterly Trend',fontsize=20)
plt.ylabel('Count',fontsize=22)
plt.xticks(fontsize=14)
sns.countplot(x='QuarterYear',data=data)
plt.savefig('QuarterlyTrend.png',dpi=300)

"""Now, we can see that 2015, and 2016 saw most number of startups being funded. highest being in Quarter 3 of 2015. Then it started declining in 2017 Q1 to 166 startups and 2017 Q4 down to only 52 startups being funded

# **Q5. which City has maximum startups?**
"""

cities=data[data['CityLocation']!='Not Specified']
cities=cities['CityLocation'].value_counts().sort_values(ascending=False).head(10)
cities

plt.figure(figsize=(20,10))
plt.title('Number of Startups in each City',fontsize=29)
plt.ylabel('Cities',fontsize=25)
plt.xlabel('Count',fontsize=25)
sns.barplot(cities.values,cities.index,palette='hot')
plt.show()

"""As we see from the graph above, maximum number of startups are based in Banglore (26.72%), followed by Mumbai (18.9%), New Delhi (16.2%), and Gurgaon (10.16%)

72% of the startups funded between January 2015 till December 2017 are based in the above mentioned four cities.

# **Q6. Who are the Top Investors by number of startups funded.**
"""

data['InvestorsName'].describe()

data['InvestorsName'].values[0]

"""There are several spelling for undisclosed investors, so let's clean that up."""

def investors_cleaner(x):
    b=str(x).lower()
    if 'undisclosed' in b:
        return 'Undisclosed Investor'
    else:
        return x

data['InvestorsName']=data['InvestorsName'].apply(investors_cleaner)

"""We see that a startup can be funded by multiple investors separated by commas. So let's make a new column 'NumberOfInvestors' which counts the number of investors for a particular startup"""

def investors_counter(x):
    l=x.split(',')
    return len(l)

data['NumberOfInvestors']=data['InvestorsName'].apply(investors_counter)

"""To find out the Investor who has funded maximum number of companies, we need to devise a way because some companies have multiple investors and we need to search each row for occurence of each investors name and count it. We will use re.search() method for this task. Below is the devised algorithm to find out actual number of startups funded by each investor by analysing rows with multiple investor names

**Note:** I do not take into account that startups have got multiple fundings at different point of times, i am just counting number of startups that were funded by each investor once, or more than once.
"""

investors_companies_funded={}
unique_name=data['InvestorsName'].unique()
name=np.array(data['InvestorsName'].values)
for i in range(len(unique_name)):
    for j in range(len(name)):
        if(re.search(unique_name[i],name[j])):
            investors_companies_funded[unique_name[i]]=investors_companies_funded.get(unique_name[i],0)+1

lst_investors = pd.DataFrame({'Name':list(investors_companies_funded.keys()),'Number of Startups Funded':list(investors_companies_funded.values())}).sort_values('Number of Startups Funded',ascending=False)

lst_investors[lst_investors['Name']!='Undisclosed Investor'].head(10)

"""The below code allows us to find the startups funded by each investor by passing in investor name as parameter. (Note: Some startups have more than one investors)"""

temp=investors_companies_funded
del temp['Undisclosed Investor']
index=list(temp.keys())
values=list(temp.values())

graph_data=pd.Series(values,index=index).sort_values(ascending=False).head(10)
graph_data=ticks_display_cleaner(graph_data)
plt.figure(figsize=(23,10))
plt.xlabel('Investors',fontsize=19)
plt.ylabel('Count',fontsize=19)
plt.title('Count of number of Startups Funded by Investors',fontsize=25)
plt.xticks(fontsize=14)
sns.barplot(graph_data.index,graph_data.values,palette='hot')
plt.savefig('Investors.png',dpi=300)

def startup_finder(investor):
    rows=[]
    for i,v in zip(data['InvestorsName'].index,data['InvestorsName'].values):
        if re.search(investor,v):
            rows.append(i)
    return data.iloc[rows,:]

"""# **Q7. Which are the most common Investment types?**"""

data['InvestmentType'].value_counts()

"""Joining duplicate values with different spellings."""

data['InvestmentType'].replace('SeedFunding','Seed Funding',inplace=True)
data['InvestmentType'].replace('PrivateEquity','Private Equity',inplace=True)

data['InvestmentType'].value_counts()

graph_data=data['InvestmentType'].value_counts()
plt.figure(figsize=(13,8))
plt.ylabel('Count',fontsize=19)
plt.title('Common Investment Types',fontsize=19)
sns.barplot(graph_data.index,graph_data.values)
plt.savefig('CommonInvestmentTypes.png',dpi=300)

"""# **Conclusion**
So, this was all our analysis, we got to know about the industries favored by investors, common investment types, and many more interesting observations about the Indian Startup Ecosystem. We also got to know that the year 2015 and 2016 were the booming years for Indian startups, with the most number of startups funded, and gradually started declining in 2017. A factor that could contribute to this sharp decline would be the announcement of Demonetization by the Indian Government in November 2016.
"""